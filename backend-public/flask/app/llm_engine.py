import os
import re
import json
from typing import List, Optional

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from pydantic import BaseModel, Field

# ==========================================
# 1. ì„¤ì • ë° ì „ì—­ ë³€ìˆ˜
# ==========================================

# Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ê²½ë¡œ ì„¤ì • (í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)
VECTOR_STORE_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "faiss_index")
EMBEDDING_MODEL = "text-embedding-3-small"

# ì „ì—­ ë³€ìˆ˜ (ë©”ëª¨ë¦¬ ë¡œë“œìš©)
vector_store = None
retriever = None

# ==========================================
# 2. ë°ì´í„° ëª¨ë¸ (Pydantic)
# ==========================================

class RecipeDetail(BaseModel):
    name: str = Field(description="Original recipe name")
    url: str = Field(description="Recipe URL")
    category: str = Field(description="Nationality/Category")
    ingredients: List[str] = Field(description="List of ingredients with quantities")
    steps: List[str] = Field(description="Detailed cooking steps")

class ChefOutput(BaseModel):
    # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì–µì§€ ìƒì„±ì„ ë§‰ê¸° ìœ„í•œ í”Œë˜ê·¸
    found_match: bool = Field(description="True if a suitable recipe was found among candidates, False otherwise.")
    best_recipe: Optional[RecipeDetail] = Field(
        description="The SINGLE best matching recipe. Set to null/empty if found_match is False."
    )
    selection_reason: str = Field(
        description="Why this recipe was chosen OR why no suitable recipe was found."
    )

# ==========================================
# 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================

def detect_language(text: str) -> str:
    """ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ê°ì§€í•©ë‹ˆë‹¤ (í•œê¸€ í¬í•¨ ì—¬ë¶€)."""
    if re.search("[ê°€-í£]", text):
        return "Korean"
    return "English"

def format_docs_for_selection(docs) -> str:
    """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ 1ë‹¨ê³„ Selectorê°€ ì½ê¸° í¸í•œ í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
    formatted = ""
    for i, doc in enumerate(docs):
        url = doc.metadata.get("url", "")
        if not url:
            url = doc.metadata.get("source", "")
        formatted += f"[Candidate {i+1}]\nURL: {url}\nContent: {doc.page_content}\n---\n"
    return formatted

# ==========================================
# 4. ì´ˆê¸°í™” í•¨ìˆ˜ (ì„œë²„ ì‹œì‘ ì‹œ í˜¸ì¶œ)
# ==========================================

def load_data_from_db(db_session=None):
    """
    ì„œë²„ ì‹œì‘ ì‹œ í˜¸ì¶œë˜ì–´ FAISS ì¸ë±ìŠ¤ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•©ë‹ˆë‹¤.
    """
    global vector_store, retriever
    
    print(f"ğŸ” [LLM Engine] FAISS ì¸ë±ìŠ¤ ë¡œë”© ì¤‘... ê²½ë¡œ: {VECTOR_STORE_PATH}")

    if not os.path.exists(VECTOR_STORE_PATH):
        print(f"ğŸš¨ [LLM Engine] ì˜¤ë¥˜: '{VECTOR_STORE_PATH}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            print("ğŸš¨ [LLM Engine] OPENAI_API_KEYê°€ í™˜ê²½ ë³€ìˆ˜ì— ì—†ìŠµë‹ˆë‹¤.")
            return

        embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL, openai_api_key=api_key)
        
        # ë¡œì»¬ FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        vector_store = FAISS.load_local(
            VECTOR_STORE_PATH, 
            embeddings, 
            allow_dangerous_deserialization=True
        )
        
        # Retriever ìƒì„± (Selectorì—ê²Œ ì¶©ë¶„í•œ í›„ë³´êµ° ì œê³µì„ ìœ„í•´ k=10 ì„¤ì •)
        retriever = vector_store.as_retriever(search_kwargs={"k": 10})
        print("âœ… [LLM Engine] FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ! (k=10)")
        
    except Exception as e:
        print(f"ğŸš¨ [LLM Engine] FAISS ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

# ==========================================
# 5. íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ í•¨ìˆ˜ (Stage 1, 2, 3)
# ==========================================

def run_stage1_selector(docs, user_question, model_name):
    """[1ë‹¨ê³„] í›„ë³´êµ° ì¤‘ì—ì„œ ìµœì ì˜ ë ˆì‹œí”¼ 1ê°œ ì„ ì • (ì—†ìœ¼ë©´ ê±°ì ˆ)"""
    llm = ChatOpenAI(model=model_name, temperature=0, openai_api_key=os.environ.get("OPENAI_API_KEY"))
    parser = JsonOutputParser(pydantic_object=ChefOutput)

    # found_match ë¡œì§ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸
    template = """
    Role: Executive Head Chef & Food Critic.
    Task: You are given {num_docs} candidate recipes. Select the ONE best recipe that perfectly matches the [User Question].

    **Process**:
    1. **Analyze**: Read the [User Question] (e.g., 'Vegan American dish') and Candidates (e.g., Kimchi fried rice) carefully.
    2. **Compare & Assess**: Evaluate if *any* candidate is a genuinely good match for the user's intent.
    3. **Decision**:
        - If a **PERFECT** match is found, set 'found_match' to True and extract the details.
        - If **NO** candidate is even a *close* match (e.g., user asks for 'Vegan' but all docs contain 'Meat', or asks for 'American' but all docs are 'Korean'), set 'found_match' to **False**.

    **Rules**:
    - Ignore recipes that are irrelevant or have empty content.
    - If the category is wrong in the doc, correct it when extracting the data.
    - **CRITICAL**: If 'found_match' is False, set 'best_recipe' to null/empty and use the 'selection_reason' to explain *why* no suitable recipe was chosen. DO NOT invent a recipe or select a non-matching one.
    
    [User Question]: {question}
    [Candidate Documents]:
    {context}
    
    [Format Instructions]: {format_instructions}
    """
    
    chain = ChatPromptTemplate.from_template(template) | llm | parser
    
    return chain.invoke({
        "num_docs": len(docs),
        "question": user_question,
        "context": format_docs_for_selection(docs),
        "format_instructions": parser.get_format_instructions()
    })

def run_stage2_generator(extracted_data, user_question, model_name):
    """[2ë‹¨ê³„] JSON ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ í¬ë§·íŒ… ë° ë²ˆì—­ (ì°½ì˜ì„± 0%, Strict Mode)"""
    # temperatureë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë¬´ì‘ìœ„ì„±ì„ ì™„ì „íˆ ì œê±°
    llm = ChatOpenAI(model=model_name, temperature=0, openai_api_key=os.environ.get("OPENAI_API_KEY"))

    recipe_info = extracted_data['best_recipe']
    reason = extracted_data['selection_reason']
    
    # [ë””ë²„ê¹…] ì‹¤ì œë¡œ 1ë‹¨ê³„ì—ì„œ ë„˜ì–´ì˜¨ ë°ì´í„°ê°€ ë¬´ì—‡ì¸ì§€ ì½˜ì†”ì—ì„œ í™•ì¸ (ì„œë²„ ë¡œê·¸ìš©)
    print(f"\nğŸ” [Debug] Stage 2ë¡œ ë„˜ì–´ì˜¨ ì›ë³¸ ë°ì´í„°:\n{json.dumps(recipe_info, indent=2, ensure_ascii=False)}\n")

    template = """
    Role: Technical Data Translator & Formatter. (NOT a Chef)
    Task: Convert the provided [JSON Data] into a specific Markdown format in ENGLISH.

    **CRITICAL RULES (VIOLATION = FAIL)**:
    1. **NO CREATIVITY**: Do NOT generate, invent, or hallucinate any new ingredients or steps.
    2. **STRICT TRANSLATION**: Only translate the values inside the JSON into English.
    3. **QUANTITY**: If the JSON does not specify quantities (e.g., "salt"), write ONLY "Salt". Do NOT guess "1 tsp Salt".
    4. **INTEGRITY**: If the JSON 'steps' list has 3 items, your output MUST have exactly 3 steps.

    **Input Data**:
    {recipe_data}

    **Target Output Format**:
    
    ### ğŸ³ {recipe_name} [[Link]]({recipe_url})
    
    **Cuisine**: {recipe_category}
    
    **Ingredients**:
    (List items exactly as found in JSON 'ingredients')
    
    **ğŸ‘¨â€ğŸ³ Instructions**:
    (List items exactly as found in JSON 'steps')
    
    ---
    ### ğŸŒŸ Selection Reason
    {selection_reason}
    
    [User Question]: {question}
    """
    
    chain = ChatPromptTemplate.from_template(template) | llm | StrOutputParser()
    
    # í”„ë¡¬í”„íŠ¸ì— ë³€ìˆ˜ë¥¼ ë” ëª…í™•í•˜ê²Œ ë¶„ë¦¬í•´ì„œ ì£¼ì…
    return chain.invoke({
        "question": user_question,
        "selection_reason": reason,
        "recipe_name": recipe_info.get('name', 'No Name'),
        "recipe_url": recipe_info.get('url', '#'),
        "recipe_category": recipe_info.get('category', 'Unknown'),
        "recipe_data": json.dumps(recipe_info, ensure_ascii=False), # ì „ì²´ ë°ì´í„°ë„ ì°¸ì¡°ìš©ìœ¼ë¡œ ì œê³µ
    })

def run_stage3_translator(english_recipe_text, target_lang, model_name):
    """[3ë‹¨ê³„] ìµœì¢… ì–¸ì–´ë¡œ ë²ˆì—­"""
    llm = ChatOpenAI(model=model_name, temperature=0.3, openai_api_key=os.environ.get("OPENAI_API_KEY"))

    template = """
    You are a professional Translator & Executive Head Chef.
    Your GOAL is to translate the provided [Recipe Text] into **{language}** perfectly.

    **CRITICAL TRANSLATION RULES**:
    1. **Translate EVERYTHING**: You must translate NOT ONLY the headers but also the **Ingredient List**, **Step-by-step Instructions**, and especially the **Selection Reason** at the bottom.
    2. **Selection Reason**: The text under "Selection Reason" or "Chef's Pick" MUST be translated into {language}. Do not leave it in English.
    3. **Ingredients & Steps**: Translate ingredient names and cooking actions into natural {language} terms (e.g., '1 tsp' -> '1 ì‘ì€ìˆ ', 'Drain' -> 'ë¬¼ê¸°ë¥¼ ë¹¼ë‹¤').
    4. **Tone**: Use a polite and warm Chef's tone (e.g., Korean: "~í•˜ì„¸ìš”", "~ì…ë‹ˆë‹¤").
    5. **Format**: Keep the Markdown structure (###, **, -) and emojis exactly as they are.

    **[Input Recipe Text]**:
    {text}
    
    **[Output in {language}]**:
    """
    
    chain = ChatPromptTemplate.from_template(template) | llm | StrOutputParser()
    
    return chain.invoke({
        "language": target_lang,
        "text": english_recipe_text
    })

# ==========================================
# 6. ë©”ì¸ í˜¸ì¶œ í•¨ìˆ˜ (ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤)
# ==========================================

def get_recipe_recommendations(question: str, model_type: str = "4o_mini"):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸(Selection -> Generation -> Translation)ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    global retriever

    # 1. ì´ˆê¸°í™” í™•ì¸
    if not retriever:
        load_data_from_db()
        if not retriever:
            return question, "ì£„ì†¡í•©ë‹ˆë‹¤. ë ˆì‹œí”¼ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # ëª¨ë¸ ì„ íƒ
    current_model = "gpt-4o-mini" if model_type == "4o_mini" else "gpt-3.5-turbo"
    
    try:
        # 2. ì–¸ì–´ ê°ì§€
        target_lang = detect_language(question)
        
        # 3. ë¬¸ì„œ ê²€ìƒ‰ (Retrieval)
        retrieved_docs = retriever.invoke(question)
        
        # ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì€ ë¬¸ì„œëŠ” í•„í„°ë§
        valid_docs = [doc for doc in retrieved_docs if len(doc.page_content.strip()) >= 30]

        if not valid_docs:
            if target_lang == "Korean":
                return question, "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ë ˆì‹œí”¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            return question, "Sorry, I couldn't find any relevant recipe information."

        # 4. Pipeline ì‹¤í–‰
        
        # [Stage 1] Selector
        selection_result = run_stage1_selector(valid_docs, question, current_model)
        if not selection_result:
            return question, "ì ì ˆí•œ ë ˆì‹œí”¼ë¥¼ ì„ ë³„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        # ê±°ë¶€ ì‘ë‹µ ì²˜ë¦¬ (ì¡°ê±´ ë¶ˆì¼ì¹˜ ì‹œ)
        if not selection_result.get('found_match', False):
            reason = selection_result.get('selection_reason', '')
            if target_lang == "Korean":
                return question, f"ğŸ˜” ìš”ì²­í•˜ì‹  ì¡°ê±´ì— ë§ëŠ” ë ˆì‹œí”¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\nì´ìœ : {reason}"
            else:
                return question, f"ğŸ˜” No suitable recipe found for your request.\nReason: {reason}"

        # [Stage 2] Generator (English Base)
        english_draft = run_stage2_generator(selection_result, question, current_model)

        # [Stage 3] Translator (Target Language)
        final_response = run_stage3_translator(english_draft, target_lang, current_model)

        return question, final_response

    except Exception as e:
        print(f"ğŸš¨ [LLM Engine] ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return question, f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


